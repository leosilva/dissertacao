% Considerações finais
\chapter{Conclusão} \label{ch:conclusao}

Este trabalho apresentou uma ferramenta web, chamada \textit{\toolName} cujo objetivo é aplicar técnicas de visualização de software para ajudar desenvolvedores e arquitetos a analisar a evolução do atributo de qualidade de desempenho, em termos de tempo de execução, ao longo das versões de um software. Essa ferramenta foi implementada como extensão a outra já existente, o \textit{\perfMinerName}. Foram implementadas duas visualizações:
\begin{itemize}
	\item \textit{Sumarização de Cenários}: visualização que apresenta uma visão geral dos cenários com desvios de desempenho, onde o usuário é capaz de distinguir se um cenário foi degradado ou otimizado, qual o cenário com maior tempo de execução e qual possuiu o maior desvio de desempenho dentre os apresentados;
	\item \textit{Grafo de Chamadas}: objetiva mostrar, para determinado cenário, os métodos que potencialmente causaram o desvio de desempenho. Tais métodos são dispostos em um grafo de chamadas com propriedades visuais que destacam quais deles tiveram desvios de desempenho, foram adiconados ou removidos, além de exibir os \textit{commits} que possívelmente foram os causadores desses desvios.
\end{itemize}

Foi conduzido um estudo onde a ferramenta foi aplicada a dois sistemas reais \textit{open-source} de diferentes domínios: Jetty e VRaptor. Para tanto, foram escolhidas dez releases de cada sistema. As visualizações geradas após a análise dessas releases foram, de maneira geral, corretas e satisfatórias. Os cenários, métodos e \textit{commits} foram devidamente representados nas visualizações através das propriedades visuais definidas. Após isso, foi aplicado um questionário online onde os contribuidores do GitHub dos sistemas analisados puderam verificar e dar feedback sobre a ferramenta e suas visualizações.

Através dos estudos conduzidos, espera-se que os desenvolvedores e arquitetos dos sistemas sejam beneficiados ao dispor de uma ferramenta para gerenciar a evolução do atributo de qualidade de desempenho, identificando as causas dos desvios de desempenho das aplicações, tomar ações para sanar problemas inesperados, além de acompanhar a evolução, planejada ou não, desse atributo de qualidade.

O restante deste capítulo está organizado como segue: a seção \ref{sec:consideracoes-questoes-pesquisa} revisita as questões de pesquisa; na seção \ref{sec:consideracoes-limitacoes} são mostradas as limitações do trabalho e a seção \ref{sec:consideracoes-trabalhos-futuros} apresenta perspectivas para trabalhos futuros e melhorias da ferramenta.

\section{Revisão das Questões de Pesquisa} \label{sec:consideracoes-questoes-pesquisa}

Baseado nos resultados obtidos do estudo realizado e apesar das suas limitações, esta seção revisita as questões de pesquisa deste trabalho. São elas:

\begin{itemize}
  \item[\textbf{QP1.}] \textbf{Os cenários identificados com desvios de desempenho são apresentados claramente nas visualizações implementadas pela ferramenta?} Após aplicação da ferramenta nos sistemas escolhidos, os cenários identificados com desvios de desempenho foram representados nas visualizações da sumarização de cenários, uma para cada par de releases, de cada sistema. A maioria dos das visualizações (10 de 15) geradas apresentou os cenários de maneira clara, onde o usuário pode distinguir, sem prejuízos, qual o cenário com maior/menor porcentagem de degradação, qual o cenário com maior/menor tempo de execução e qual o tipo de desvio de desempenho (otimização ou degradação) de cada cenário. Das 5 visualizações restantes, em 4 delas a identificação das características comentadas anteriormente foi prejudicada pela quantidade de cenários apresentados na visualização e pela baixa porcentagem de desvio de parte desses cenários em relação aos demais. Para a visualização restante, foi impossível identificar o cenário com maior tempo de execução, pois a sua baixa porcentagem de desvio em relação aos demais tornou impossível distingui-lo visualmente no gráfico de rosca.
  \item[\textbf{QP2.}] \textbf{O algoritmo de redução de nós aplicado pela ferramenta é capaz de reduzir significativamente o número de nós no grafo de chamadas para sistemas reais?} A visualização do grafo de chamadas para cada cenário foi gerada a partir dos dados da hierarquia de chamadas provenientes das análises realizadas nos sistemas. Para 75\% dos cenários, o algoritmo de supressão de nós conseguiu reduzir entre 73,77\% e 99,83\% a quantidade de nós a serem mostrados no grafo. Esse número, em quantidade de nós, é de 2 a 16 nós exibidos no grafo de chamadas.
  \item[\textbf{QP3.}] \textbf{Desenvolvedores e arquitetos conseguem identificar os cenários com variações de desempenho e suas potenciais causas, em termos de métodos e \textit{commits}, através do auxílio visual da ferramenta?} Com o feedback obtido dos participantes do questionário online, verificou-se que a maioria deles (67\%) indicou corretamente os métodos, suas características e \textit{commits} utilizando a visualização do grafo de chamadas. No entanto, para a visualização da sumarização de cenários, não é possível afirmar que esta trouxe ganhos para a identificação dos cenários, uma vez que apenas metade (50\%) dos participantes que a avaliaram conseguiram identificar corretamente os cenários e suas propriedades.
  \item[\textbf{QP4.}] \textbf{Há indícios de que as visualizações implementadas pela ferramenta são mais eficazes do que os dados tabulares para se encontrar informações sobre os cenários, métodos e \textit{commits}?} Também após o feedback obtido dos participantes do questionário online, houve indícios de que a visualização do grafo de chamadas se mostrou mais eficaz do que os dados tabulares (isto é, desconsiderando a existência dessa visualização) para se encontrar informações sobre os métodos responsáveis pelos desvios de desempenho de determinado cenário e os \textit{hashs} dos \textit{commits} potencialmente responsáveis por esse desvio. No entanto, para a visualização da sumarização de cenários, não houve indícios suficientes como concluir se a visualização é mais eficaz do que os dados tabulares para identificar os cenários e suas propriedades.
\end{itemize}

\section{Limitações} \label{sec:consideracoes-limitacoes}

Este trabalho possui limitações no tocante à ferramenta e sua implementação, conforme descritas a seguir nesta seção.

\subsection{Segurança e Desempenho} \label{subsec:consideracoes-limitacoes-seguranca-desempenho}

A implementação do \textit{\toolName} não levou em consideração requisitos não-funcionais como segurança e desempenho da própria aplicação. Nesse sentido, com relação à segurança, não há verificações dos usuários que utilizam a ferramenta nem quais funcionalidades eles podem acessar. Já com relação ao desempenho, não foram estabelecidas restrições de desempenho como velocidade da resposta de processamento em telas ou o tempo de resposta em processamentos específicos, como o processamento em lote. A implementação do banco de dados QAV serve como um \textit{cache}, minimizando o tempo de resposta na requisição a uma visualização, no entanto, o seu propósito primário é armazenar os dados resultantes do processamento em lote.

\subsection{Escalabilidade} \label{subsec:consideracoes-limitacoes-escalabilidade}

Conforme mostrado na subseção \ref{subsec:avaliacao-comportamento-sumarizacao-cenarios}, existem limitações com relação a escalabilidade da visualização da sumarização de cenários. Para a análise de um par de releases, quando a quantidade de cenários indicados com desvios de desempenho é grande (acima de 20) e há cenários com baixas porcentagens de desvio de desempenho em relação aos demais, a identificação destes pode ser prejudicada ou até mesmo inviabilizada.

O grafo de chamadas também possui limitações de escalabilidade. A quantidade dos nós com desvios de desempenho de uma versão para outra de um software pode ser grande de modo a comprometer o desempenho da própria visualização, comprometer a sua usabilidade e visibilidade ou, até mesmo, inviabilizá-la. Embora medidas tenham sido tomadas para minimizar esse impacto - como, por exemplo, o agrupamento de nós não relacionados com nós de desvio, adicionados ou removidos - há possibilidades de acontecer.

No caso de serem analisadas duas versões muitos distantes entre si, podem existir muitas modificações, fazendo com que o grafo gerado seja grande e complexo, resultando no problema do tamanho do grafo apresentado no parágrafo anterior. O ideal ao utilizar a ferramenta é analisar versões próximas para beneficiar-se da baixa granularidade apresentada pelo grafo de chamadas.

\subsection{Acessibilidade} \label{subsec:consideracoes-limitacoes-acesibilidade}

A ferramenta proposta faz constante uso de cores para distinguir cenários e nós com propriedades diferentes. Dessa maneira, espera-se que os usuários, através dessa propriedade visual, consiga identificar corretamente os desvios de desempenho, o que pode não acontecer com usuários com problemas de visão. Até o momento da escrita deste trabalho, a ferramenta não pode ser considerada acessível por não dispor de mecanismos de acessibilidade para cegos, daltônicos, surdos (apesar de não fazer uso de mídias auditivas) e pessoas com baixa visão.

\subsection{Automatização} \label{subsec:consideracoes-limitacoes-automatizacao}

A análise do desempenho dos cenários contidos nas versões dos sistemas é feita de forma automatizada pelo \textit{\perfMinerName}, entretanto, é reconhecido que ainda há passos manuais a serem feitos, conforme destacado na subseção \ref{subsec:avaliacao-procedimentos}: (i) os códigos-fonte das versões são baixados e configurados manualmente para executar sem erros; (ii) a configuração do suporte ao \textit{AspectJ} e a inclusão das bibliotecas do próprio \textit{\perfMinerName} são realizadas manualmente; (iii) o início da execução dos testes é dado de forma manual, mesmo que se utilize ferramentas que automatizam a execução de cada teste, como o Maven ou o Gradle\footnote{\href{https://gradle.org}{https://gradle.org}}; e (iv) os artefatos de saída da execução do \textit{\perfMinerName} são importados manualmente na ferramenta \textit{\toolName}, através da funcionalidade de Nova Análise (\ref{subsec:new-analysis}).

\subsection{Dispositivos Móveis}

Embora seja uma ferramenta web, pode ser considerada uma limitação o não suporte a dispositivos móveis, sejam eles tablets ou smartphones. Através desses dispositivos é possível acessar a ferramenta, no entanto, por não dispor de mecanismos responsivos validados para este fim, as informações podem ser apresentadas nas visualizações de maneira indesejada.

Um dos participantes (P2GA) do questionário online acessou a ferramenta através do seu celular para responder às questões. Entretanto, como as visualizações abriram de maneira inadequada, suas respostas foram comprometidas, o que fez com que a resposta desse participante fosse invalidada.

Também pode ser considerada uma limitação, herdada do \textit{PerfMiner}, o fato de o conjunto de visualizações apresentar apenas dados do atributo de qualidade de  desempenho. No entanto, a ferramenta está apta a atender a outros atributos de qualidade.

\section{Trabalhos Futuros} \label{sec:consideracoes-trabalhos-futuros}

Há planos de trabalhos a serem feitos de modo a incrementar a implementação da ferramenta e os resultados obtidos.

\subsection{Atributos de Qualidade Adicionais}

A ferramenta apresenta a evolução do desempenho dos cenários das versões de um sistema em termos de tempo de execução. Para determinados sistemas, outros atributos de qualidade podem ser tão ou mais importantes do que o desempenho. Como trabalho futuro, a ferramenta pode ser expandida para medir o desempenho a partir de outras propriedades, como consumo de memória, atividades de disco e uso de CPU, mas também pode ser adicionado o suporte para novos atributos de qualidade, como segurança e confiabilidade. Um dos desafios encontrados ao se expandir a ferramenta para outros atributos de qualidade é como medi-los. É provável que para representar os novos atributos de qualidade seja necessário implementar novas visualizações com novas metáforas visuais de acordo com as características do atributo de qualidade desejado.

\subsection{Aplicação em um Ambiente Real de Desenvolvimento}

A maioria dos participantes indicou que utilizaria a ferramenta como parte integrante dos seus processos de desenvolvimento de software. A ferramenta foi aplicada em sistemas \textit{open-source} de diferentes domínios, como o Jetty e o VRaptor. Após isso, os desenvolvedores desses sistemas acessaram as visualizações implementadas para responder ao questionário online. Planeja-se implantar a ferramenta em um ambiente real de desenvolvimento para que os desenvolvedores e arquitetos experimentem, na prática, a sua utilização ao longo das releases do sistema. Uma empresa candidata é a \abrv[SINFO -- Superintendência de Informática]{Superintendência de Informática (SINFO)}da UFRN pelo fato de ser uma empresa sediada na universidade, de fácil acesso e possuir produtos desenvolvidos na linguagem Java.

\subsection{Novas Avaliações}

As avaliações realizadas neste trabalho incluíram a aplicação da ferramenta em dois sistemas reais de diferentes domínios e a aplicação do questionário junto aos desenvolvedores desses sistemas. Há planos para que sejam feitas mais avaliações a fim de obter mais indícios sobre a utilidade da ferramenta e suas visualizações. Tais estudos seriam:
\begin{enumerate}[(i)]
	\item \textit{Aplicar a abordagem em sistemas open-source}: outros sistemas \textit{open-source} seriam escolhidos e então a abordagem seria aplicada. Após isso, o questionário seria submetido aos desenvolvedores e arquitetos desses sistemas, como foi feito no estudo relatado neste trabalho;
	\item \textit{Experimento controlado I}: a partir dos mesmos resultados já obtidos, realizar um experimento controlado com desenvolvedores e arquitetos de empresas da cidade de Natal/RN. Dessa forma, o questionário poderia ser modificado para incluir outros aspectos não medidos neste trabalho, como a usabilidade;
	\item \textit{Experimento controlado II}: contactar os representantes de empresas de desenvolvimento da cidade de Natal/RN com a finalidade de aplicar a ferramenta em seus sistemas. Após isso, convidar os desenvolvedores desses sistemas para um experimento controlado, aplicando um questionário para coletar feedback sobre as visualizações. Assim como no ponto anterior, o questionário poderia ser modificado para incluir aspectos ainda não avaliados.
\end{enumerate}

\subsection{Novas Estratégias para Exercitar os Cenários} \label{subsec:consideracoes-novas-estrategias-exercitar-cenarios}

Como discutido na subseção \ref{subsec:avaliacao-consideracoes-testes-unitarios}, a ferramenta utiliza atualmente casos de testes automatizados para execitar os cenários e realizar a análise, estratégia essa que foi criticada por um dos participantes do estudo (P11GA). No entanto, outras estratégias também são válidas, pois a ferramenta continuará apontando os cenários com desvios de desempenho. Nesse sentido, há planos futuros para que a ferramenta permita a configuração dos cenários desejados a serem considerados na análise, de maneira não intrusiva. Dessa forma, os usuários poderão escolher os cenários que devem ter o desempenho medido pela ferramenta, de acordo com as regras de negócio dos seus sistemas.

\subsection{Automatização} \label{subsec:consideracoes-automatizacao}

A abordagem realiza a comparação automática de duas releases de um sistema, indicando os cenários com desvios de desempenho. Embora essa comparação seja automática, há ainda passos manuais a serem executados, conforme destacado na subseção \ref{subsec:avaliacao-procedimentos} e comentado novamente na subseção \ref{subsec:consideracoes-limitacoes-automatizacao}. Como trabalho futuro, planeja-se automatizar os passos executados manualmente, como a obtenção dos códigos-fonte das releases, configuração do suporte ao \textit{AspectJ} e ao \textit{\perfMinerName}, execução da ferramenta e a importação dos artefatos de saída para o \textit{\toolName}.

\subsection{Customização} \label{subsec:consideracoes-customizacao}

{\color{red}CONTINUAR...}

\subsection{Disponibilização para a Comunidade}

O questionário online mostrou que a maioria dos participantes veem benefícios em se utilizar a ferramenta proposta e também a utilizariam como parte integrante de seus processos de desenvolvimento. A partir desse feedback, há planos futuros de disponibilizar a ferramenta para a comunidade para que desenvolvedores façam uso e tirem proveito de suas funcionalidades. Dentre as maneiras de se fazer isso, incluem o desenvolvimento e disponibilização de \textit{plugins} para ferramentas de integração contínua como o Hudson CI, Jenkins CI ou Travis CI, e a disponibilização de uma versão que possa ser utilizada de maneira \textit{standalone}, sem estar necessariamente integrada a ferramentas de integração contínua.

A fim de disponibilizar uma ferramenta fácil de usar, robusta e configurável, é de fundamental importância a implementação das modificações comentadas nas subseções \ref{subsec:consideracoes-novas-estrategias-exercitar-cenarios} e \ref{subsec:consideracoes-automatizacao}, além de outras que venham a ser vislumbradas durante o aprimoramento da ferramenta.